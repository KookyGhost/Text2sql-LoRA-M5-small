{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9494ada0-1c0e-4abf-9288-1a09a088fe20",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.14.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.3)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.15)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2023.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.20.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (23.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (15.0.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.9.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from datasets>=2.0.0->evaluate) (5.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->evaluate) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->evaluate) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->evaluate) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2023.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76d30ad4-2001-464a-9315-79dcfbf8eae1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting trl\n",
      "  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting accelerate>=0.34.0 (from trl)\n",
      "  Downloading accelerate-1.5.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting datasets>=2.21.0 (from trl)\n",
      "  Downloading datasets-3.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting rich (from trl)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting transformers>=4.46.0 (from trl)\n",
      "  Downloading transformers-4.50.0-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from accelerate>=0.34.0->trl) (5.4.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (2.1.1+cu121)\n",
      "Collecting huggingface-hub>=0.21.0 (from accelerate>=0.34.0->trl)\n",
      "  Downloading huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting safetensors>=0.4.3 (from accelerate>=0.34.0->trl)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (15.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (2.2.0)\n",
      "Collecting requests>=2.32.2 (from datasets>=2.21.0->trl)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.66.3 (from datasets>=2.21.0->trl)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (3.4.1)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.21.0->trl) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (3.9.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl) (2023.12.25)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers>=4.46.0->trl)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->trl)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (2.17.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate>=0.34.0->trl) (4.9.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->trl)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (2020.6.20)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.1.3)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.21.0->trl) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->datasets>=2.21.0->trl) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.21.0->trl) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.21.0->trl) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate>=0.34.0->trl) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=2.0.0->accelerate>=0.34.0->trl) (1.3.0)\n",
      "Downloading trl-0.15.2-py3-none-any.whl (318 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.5.2-py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.1/345.1 kB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-3.4.1-py3-none-any.whl (487 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.50.0-py3-none-any.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m137.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m149.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: tqdm, safetensors, requests, mdurl, markdown-it-py, huggingface-hub, tokenizers, rich, accelerate, transformers, datasets, trl\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.1\n",
      "    Uninstalling tqdm-4.66.1:\n",
      "      Successfully uninstalled tqdm-4.66.1\n",
      "  Attempting uninstall: safetensors\n",
      "    Found existing installation: safetensors 0.4.0\n",
      "    Uninstalling safetensors-0.4.0:\n",
      "      Successfully uninstalled safetensors-0.4.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.20.3\n",
      "    Uninstalling huggingface-hub-0.20.3:\n",
      "      Successfully uninstalled huggingface-hub-0.20.3\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.15.1\n",
      "    Uninstalling tokenizers-0.15.1:\n",
      "      Successfully uninstalled tokenizers-0.15.1\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.24.1\n",
      "    Uninstalling accelerate-0.24.1:\n",
      "      Successfully uninstalled accelerate-0.24.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.35.2\n",
      "    Uninstalling transformers-4.35.2:\n",
      "      Successfully uninstalled transformers-4.35.2\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.14.5\n",
      "    Uninstalling datasets-2.14.5:\n",
      "      Successfully uninstalled datasets-2.14.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gradient 2.0.6 requires attrs<=19, but you have attrs 23.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-1.5.2 datasets-3.4.1 huggingface-hub-0.29.3 markdown-it-py-3.0.0 mdurl-0.1.2 requests-2.32.3 rich-13.9.4 safetensors-0.5.3 tokenizers-0.21.1 tqdm-4.67.1 transformers-4.50.0 trl-0.15.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38073d67-cefd-4e59-9e88-286df90a3f38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 15:15:14.814900: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-21 15:15:14.814953: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-21 15:15:14.816575: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-21 15:15:14.824509: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-21 15:15:16.298606: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict, load_dataset, interleave_datasets, load_from_disk\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer, pipeline\n",
    "import torch\n",
    "import time\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "from trl import SFTTrainer, SFTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8ca0f59-c55f-414f-9a5e-19d846851007",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a727ceecdc54a849c83570b5976cd9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b92ea41e1e0149b4996c749329bee3a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6dc62edaac4dc08e69eeed3b11b2a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03147974a494d7fb00397d6ffcdd75a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "980e19a2b9474f64a77661d02aec308c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceddf2c118004e3b8eb850e8c977fef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name='t5-small'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad16028-35c6-4153-920a-098e187cbcb9",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e352efb-7809-4cf4-b8e3-81bec82e0443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "e2eba389-1b84-4559-b3f0-cd8b8d254edc",
   "metadata": {
    "tags": []
   },
   "source": [
    "try:\n",
    "    dataset = load_from_disk(\"merged_dataset\")\n",
    "    print(\"Loaded Merged Dataset\")\n",
    "except:\n",
    "    dataset_scc_train = load_dataset(\"b-mc2/sql-create-context\", split='train[:80%]')\n",
    "    dataset_scc_test  = load_dataset(\"b-mc2/sql-create-context\", split='train[-20%:-10%]')\n",
    "    dataset_scc_val   = load_dataset(\"b-mc2/sql-create-context\", split='train[-10%:]')\n",
    "\n",
    "    dataset_tts_train = load_dataset(\"Clinton/Text-to-sql-v1\", split='train[:80%]')\n",
    "    dataset_tts_train = dataset_tts_train.remove_columns(['source', 'text'])\n",
    "    dataset_tts_train = dataset_tts_train.rename_columns({'instruction': 'question', 'input': 'context', 'response': 'answer'})\n",
    "    dataset_tts_test  = load_dataset(\"Clinton/Text-to-sql-v1\", split='train[-20%:-10%]')\n",
    "    dataset_tts_test  = dataset_tts_test.remove_columns(['source', 'text'])\n",
    "    dataset_tts_test  = dataset_tts_test.rename_columns({'instruction': 'question', 'input': 'context', 'response': 'answer'})\n",
    "    dataset_tts_val   = load_dataset(\"Clinton/Text-to-sql-v1\", split='train[-10%:]')\n",
    "    dataset_tts_val   = dataset_tts_val.remove_columns(['source', 'text'])\n",
    "    dataset_tts_val   = dataset_tts_val.rename_columns({'instruction': 'question', 'input': 'context', 'response': 'answer'})\n",
    "\n",
    "    dataset_ks_train  = load_dataset(\"knowrohit07/know_sql\", split='validation[:80%]')\n",
    "    dataset_ks_test   = load_dataset(\"knowrohit07/know_sql\", split='validation[-20%:-10%]')\n",
    "    dataset_ks_val    = load_dataset(\"knowrohit07/know_sql\", split='validation[-10%:]')\n",
    "\n",
    "    dataset = DatasetDict({ 'train': interleave_datasets([dataset_scc_train, dataset_tts_train, dataset_ks_train]),\n",
    "                            'test': interleave_datasets([dataset_scc_test, dataset_tts_test, dataset_ks_test]),\n",
    "                            'validation': interleave_datasets([dataset_scc_val, dataset_tts_val, dataset_ks_val])})\n",
    "\n",
    "    dataset.save_to_disk(\"merged_dataset\")\n",
    "    print(\"Merged and Saved Dataset\")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f965504-afc2-41d5-a9fa-e189a6237a41",
   "metadata": {},
   "source": [
    "# Preprocess the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17bb1662-c429-4d7e-a434-b40d50e770bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    start_prompt = \"Tables:\\n\"\n",
    "    middle_prompt = \"\\n\\nQuestion:\\n\"\n",
    "    end_prompt = \"\\n\\nAnswer:\\n\"\n",
    "  \n",
    "    data_zip = zip(example['context'], example['question'])\n",
    "    prompt = [start_prompt + context + middle_prompt + question + end_prompt for context, question in data_zip]\n",
    "\n",
    "    # Tokenize input (context + question)\n",
    "    inputs = tokenizer(\n",
    "        prompt, \n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding = True\n",
    "    )\n",
    "\n",
    "    # Tokenize output (answer)\n",
    "    labels = tokenizer(\n",
    "        example['answer'], \n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding = True\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": inputs[\"input_ids\"],\n",
    "        \"attention_mask\": inputs[\"attention_mask\"],\n",
    "        \"labels\": labels[\"input_ids\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20387e6c-a748-4a89-8c40-28d72a880782",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Tokenized Dataset\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tokenized_datasets = load_from_disk(\"tokenized_datasets\")\n",
    "    print(\"Loaded Tokenized Dataset\")\n",
    "except:\n",
    "    tokenized_datasets = dataset.map(\n",
    "                                    tokenize_function,\n",
    "                                    batched=True,  \n",
    "                                    remove_columns=['question', 'context', 'answer'],  # Remove original text fields\n",
    "                                    load_from_cache_file=False,\n",
    "                                    desc=\"Tokenizing dataset\",\n",
    "                                )\n",
    "    \n",
    "    tokenized_datasets.save_to_disk(\"tokenized_datasets\")\n",
    "    print(\"Tokenized and Saved Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcc3676e-f885-4d03-8688-07be4228f8ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(tokenized_datasets.keys())\n",
    "# print(tokenized_datasets['train'][0].keys())\n",
    "# print(tokenized_datasets['train'][0]['input_ids'])\n",
    "# print(tokenized_datasets['train'][0]['labels'])\n",
    "# print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78ad2a11-0c0a-4649-b329-4a3ec4bb7982",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, prepare_model_for_int8_training, TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "864db7dc-9d4f-4aca-abab-1abc1ead9d38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    # target_modules=[\"q\", \"v\", \"o\", \"wi_0\", \"wi_1\", \"wo\"],\n",
    "    # modules_to_save=[\"lm_head\", \"embed_tokens\"],\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "334b0a12-411c-4bbc-97a7-5af7542aa963",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name='t5-small'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b754d91-7a13-42af-8358-472e265fc889",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 294,912 || all params: 60,801,536 || trainable%: 0.4850403779272945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/peft/utils/other.py:136: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = prepare_model_for_int8_training(model)\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "621e8e44-43ed-407c-a081-1622471291b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "label_pad_token_id = -100\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=label_pad_token_id,\n",
    "    pad_to_multiple_of=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7182139-b2f4-4c64-bd35-01ec5b09849f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = f'tunes/sql-training-{str(int(time.time()))}'\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    auto_find_batch_size=True,\n",
    "    learning_rate=5e-3,\n",
    "    num_train_epochs=2,\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=500,\n",
    "    per_device_train_batch_size=16,     # batch size per device during training\n",
    "    per_device_eval_batch_size=16,      # batch size for evaluation\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"steps\",\n",
    "    label_names = ['labels']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbf9b8c0-a555-46a9-84d9-ec5560f6d1d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 118695\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef268ff5-92f7-4ba2-8e6c-41880b5bd665",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-21 00:11:49,383] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc0c79b9-1e99-4c31-97b6-47d998eba6b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkookyghost\u001b[0m (\u001b[33mkookyghost-university-of-connecticut\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20250321_001152-wpd8zwz4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kookyghost-university-of-connecticut/huggingface/runs/wpd8zwz4' target=\"_blank\">tunes/sql-training-1742515904</a></strong> to <a href='https://wandb.ai/kookyghost-university-of-connecticut/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kookyghost-university-of-connecticut/huggingface' target=\"_blank\">https://wandb.ai/kookyghost-university-of-connecticut/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kookyghost-university-of-connecticut/huggingface/runs/wpd8zwz4' target=\"_blank\">https://wandb.ai/kookyghost-university-of-connecticut/huggingface/runs/wpd8zwz4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14838' max='14838' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14838/14838 2:21:09, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.189200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.079800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.072200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.066400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.061800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.061300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.055800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.052900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.057000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.057900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.050700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.049000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.047500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.045500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.046900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.043300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.042300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.042900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.040700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.039100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.036800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.036400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.036900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.036100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.032700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.033300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.032200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=14838, training_loss=0.05259703612902814, metrics={'train_runtime': 8471.1663, 'train_samples_per_second': 28.023, 'train_steps_per_second': 1.752, 'total_flos': 3.234385838997504e+16, 'train_loss': 0.05259703612902814, 'epoch': 2.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f841a629410>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f841a730f90, execution_count=18 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f8419af2fd0, raw_cell=\"model.config.use_cache = False\n",
      "\n",
      "trainer.train()\" store_history=True silent=False shell_futures=True cell_id=bc0c79b9-1e99-4c31-97b6-47d998eba6b9> result=TrainOutput(global_step=14838, training_loss=0.05259703612902814, metrics={'train_runtime': 8471.1663, 'train_samples_per_second': 28.023, 'train_steps_per_second': 1.752, 'total_flos': 3.234385838997504e+16, 'train_loss': 0.05259703612902814, 'epoch': 2.0})>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "model.config.use_cache = False\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea600991-24a2-47aa-8ac3-a1c3673c5b5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f841a629410>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f83bc691310, raw_cell=\"trainer.model.save_pretrained('tuned_model')\n",
      "token..\" store_history=True silent=False shell_futures=True cell_id=ea600991-24a2-47aa-8ac3-a1c3673c5b5f>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('tuned_model/tokenizer_config.json',\n",
       " 'tuned_model/special_tokens_map.json',\n",
       " 'tuned_model/spiece.model',\n",
       " 'tuned_model/added_tokens.json',\n",
       " 'tuned_model/tokenizer.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f841a629410>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f83bc406950, execution_count=20 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f83bc691310, raw_cell=\"trainer.model.save_pretrained('tuned_model')\n",
      "token..\" store_history=True silent=False shell_futures=True cell_id=ea600991-24a2-47aa-8ac3-a1c3673c5b5f> result=('tuned_model/tokenizer_config.json', 'tuned_model/special_tokens_map.json', 'tuned_model/spiece.model', 'tuned_model/added_tokens.json', 'tuned_model/tokenizer.json')>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "trainer.model.save_pretrained('tuned_model')\n",
    "tokenizer.save_pretrained('tuned_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca4c8f13-8107-474d-bac9-8da35beabd6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff528575-808f-476a-a8dc-fdaba52138f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_model_size(path):\n",
    "    size = 0\n",
    "    for f in os.scandir(path):\n",
    "        size += os.path.getsize(f)\n",
    "\n",
    "    print(f\"Model size: {(size / 1e6):.2} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daffd9a1-4050-447e-94cc-49e042a75cc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model, label):\n",
    "    parameters, trainable = 0, 0\n",
    "    \n",
    "    for _, p in model.named_parameters():\n",
    "        parameters += p.numel()\n",
    "        trainable += p.numel() if p.requires_grad else 0\n",
    "\n",
    "    print(f\"{label} trainable parameters: {trainable:,}/{parameters:,} ({100 * trainable / parameters:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "028a8b92-1a45-4ad7-bf31-5ab5ce3a00ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75072719f68843d09691ca5f3dcd8a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3bf4e24583b438588f1fe91d14d2715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a65b204d1a104d6e95d066187dfb9eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1855dffb71e44d7f80b0bbb3cafca0fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e098733b2f94ca78c9efd94da4675c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b3c09baf4a143ecae62d850ad06e382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name='t5-small'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
    "original_model = original_model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6176be1-5719-4044-a746-6cb3c603257d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model trainable parameters: 60,506,624/60,506,624 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters(original_model,'base model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b5a85d5-0c19-4030-b091-aca2719ba557",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = get_peft_model(original_model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cefc9180-176e-4b35-83fa-0a2b3aa19537",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA model trainable parameters: 294,912/60,801,536 (0.49%)\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters(model,'LoRA model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2f0dc03-cccb-4583-82a5-cef272eefa57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'T5Config' object has no attribute 'num_parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m T5ForConditionalGeneration\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt5-small\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Print the number of parameters\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_parameters\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py:214\u001b[0m, in \u001b[0;36mPretrainedConfig.__getattribute__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattribute_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattribute_map\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    213\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattribute_map\u001b[39m\u001b[38;5;124m\"\u001b[39m)[key]\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'T5Config' object has no attribute 'num_parameters'"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration\n",
    "\n",
    "# Load the model\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "# Print the number of parameters\n",
    "print(f\"Number of parameters: {model.config.num_parameters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8ca181f-b343-4815-b73c-194b8a2370d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 4.4 MB\n"
     ]
    }
   ],
   "source": [
    "print_model_size('tuned_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6fd1a81e-7f63-4ac3-9bdd-85e17cb75279",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.save_model('tuned_model_save_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8889f92d-469d-4a26-b9b7-db3d9651d9e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f841a629410>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f83d2246b90, raw_cell=\"import wandb\n",
      "wandb.finish()\n",
      "# wandb.login()  \" store_history=True silent=False shell_futures=True cell_id=8889f92d-469d-4a26-b9b7-db3d9651d9e8>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▆▅▄▅▃▂█▃▇▄▃▂▁▂▃▂▃▂▁▄▆▂▂▃▁▂▂▂▂</td></tr><tr><td>train/learning_rate</td><td>██▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>3.234385838997504e+16</td></tr><tr><td>train/epoch</td><td>2.0</td></tr><tr><td>train/global_step</td><td>14838</td></tr><tr><td>train/grad_norm</td><td>0.0454</td></tr><tr><td>train/learning_rate</td><td>0.00011</td></tr><tr><td>train/loss</td><td>0.0322</td></tr><tr><td>train_loss</td><td>0.0526</td></tr><tr><td>train_runtime</td><td>8471.1663</td></tr><tr><td>train_samples_per_second</td><td>28.023</td></tr><tr><td>train_steps_per_second</td><td>1.752</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">tunes/sql-training-1742515904</strong> at: <a href='https://wandb.ai/kookyghost-university-of-connecticut/huggingface/runs/wpd8zwz4' target=\"_blank\">https://wandb.ai/kookyghost-university-of-connecticut/huggingface/runs/wpd8zwz4</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250321_001152-wpd8zwz4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.finish()\n",
    "# wandb.login()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51d66e3a-d53c-4cfe-8e1a-576fc92c69b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import ModelCard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30dce4af-e966-4e5e-8996-cc9365feca1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Model Card for Model ID\n",
      "\n",
      "<!-- Provide a quick summary of what the model is/does. -->\n",
      "\n",
      "\n",
      "\n",
      "## Model Details\n",
      "\n",
      "### Model Description\n",
      "\n",
      "<!-- Provide a longer summary of what this model is. -->\n",
      "\n",
      "\n",
      "\n",
      "- **Developed by:** [More Information Needed]\n",
      "- **Funded by [optional]:** [More Information Needed]\n",
      "- **Shared by [optional]:** [More Information Needed]\n",
      "- **Model type:** [More Information Needed]\n",
      "- **Language(s) (NLP):** [More Information Needed]\n",
      "- **License:** [More Information Needed]\n",
      "- **Finetuned from model [optional]:** [More Information Needed]\n",
      "\n",
      "### Model Sources [optional]\n",
      "\n",
      "<!-- Provide the basic links for the model. -->\n",
      "\n",
      "- **Repository:** [More Information Needed]\n",
      "- **Paper [optional]:** [More Information Needed]\n",
      "- **Demo [optional]:** [More Information Needed]\n",
      "\n",
      "## Uses\n",
      "\n",
      "<!-- Address questions around how the model is intended to be used, including the foreseeable users of the model and those affected by the model. -->\n",
      "\n",
      "### Direct Use\n",
      "\n",
      "<!-- This section is for the model use without fine-tuning or plugging into a larger ecosystem/app. -->\n",
      "\n",
      "[More Information Needed]\n",
      "\n",
      "### Downstream Use [optional]\n",
      "\n",
      "<!-- This section is for the model use when fine-tuned for a task, or when plugged into a larger ecosystem/app -->\n",
      "\n",
      "[More Information Needed]\n",
      "\n",
      "### Out-of-Scope Use\n",
      "\n",
      "<!-- This section addresses misuse, malicious use, and uses that the model will not work well for. -->\n",
      "\n",
      "[More Information Needed]\n",
      "\n",
      "## Bias, Risks, and Limitations\n",
      "\n",
      "<!-- This section is meant to convey both technical and sociotechnical limitations. -->\n",
      "\n",
      "[More Information Needed]\n",
      "\n",
      "### Recommendations\n",
      "\n",
      "<!-- This section is meant to convey recommendations with respect to the bias, risk, and technical limitations. -->\n",
      "\n",
      "Users (both direct and downstream) should be made aware of the risks, biases and limitations of the model. More information needed for further recommendations.\n",
      "\n",
      "## How to Get Started with the Model\n",
      "\n",
      "Use the code below to get started with the model.\n",
      "\n",
      "[More Information Needed]\n",
      "\n",
      "## Training Details\n",
      "\n",
      "### Training Data\n",
      "\n",
      "<!-- This should link to a Dataset Card, perhaps with a short stub of information on what the training data is all about as well as documentation related to data pre-processing or additional filtering. -->\n",
      "\n",
      "[More Information Needed]\n",
      "\n",
      "### Training Procedure\n",
      "\n",
      "<!-- This relates heavily to the Technical Specifications. Content here should link to that section when it is relevant to the training procedure. -->\n",
      "\n",
      "#### Preprocessing [optional]\n",
      "\n",
      "[More Information Needed]\n",
      "\n",
      "\n",
      "#### Training Hyperparameters\n",
      "\n",
      "- **Training regime:** [More Information Needed] <!--fp32, fp16 mixed precision, bf16 mixed precision, bf16 non-mixed precision, fp16 non-mixed precision, fp8 mixed precision -->\n",
      "\n",
      "#### Speeds, Sizes, Times [optional]\n",
      "\n",
      "<!-- This section provides information about throughput, start/end time, checkpoint size if relevant, etc. -->\n",
      "\n",
      "[More Information Needed]\n",
      "\n",
      "## Evaluation\n",
      "\n",
      "<!-- This section describes the evaluation protocols and provides the results. -->\n",
      "\n",
      "### Testing Data, Factors & Metrics\n",
      "\n",
      "#### Testing Data\n",
      "\n",
      "<!-- This should link to a Dataset Card if possible. -->\n",
      "\n",
      "[More Information Needed]\n",
      "\n",
      "#### Factors\n",
      "\n",
      "<!-- These are the things the evaluation is disaggregating by, e.g., subpopulations or domains. -->\n",
      "\n",
      "[More Information Needed]\n",
      "\n",
      "#### Metrics\n",
      "\n",
      "<!-- These are the evaluation metrics being used, ideally with a description of why. -->\n",
      "\n",
      "[More Information Needed]\n",
      "\n",
      "### Results\n",
      "\n",
      "[More Information Needed]\n",
      "\n",
      "#### Summary\n",
      "\n",
      "\n",
      "\n",
      "## Model Examination [optional]\n",
      "\n",
      "<!-- Relevant interpretability work for the model goes here -->\n",
      "\n",
      "[More Information Needed]\n",
      "\n",
      "## Environmental Impact\n",
      "\n",
      "<!-- Total emissions (in grams of CO2eq) and additional considerations, such as electricity usage, go here. Edit the suggested text below accordingly -->\n",
      "\n",
      "Carbon emissions can be estimated using the [Machine Learning Impact calculator](https://mlco2.github.io/impact#compute) presented in [Lacoste et al. (2019)](https://arxiv.org/abs/1910.09700).\n",
      "\n",
      "- **Hardware Type:** [More Information Needed]\n",
      "- **Hours used:** [More Information Needed]\n",
      "- **Cloud Provider:** [More Information Needed]\n",
      "- **Compute Region:** [More Information Needed]\n",
      "- **Carbon Emitted:** [More Information Needed]\n",
      "\n",
      "## Technical Specifications [optional]\n",
      "\n",
      "### Model Architecture and Objective\n",
      "\n",
      "[More Information Needed]\n",
      "\n",
      "### Compute Infrastructure\n",
      "\n",
      "[More Information Needed]\n",
      "\n",
      "#### Hardware\n",
      "\n",
      "[More Information Needed]\n",
      "\n",
      "#### Software\n",
      "\n",
      "[More Information Needed]\n",
      "\n",
      "## Citation [optional]\n",
      "\n",
      "<!-- If there is a paper or blog post introducing the model, the APA and Bibtex information for that should go in this section. -->\n",
      "\n",
      "**BibTeX:**\n",
      "\n",
      "[More Information Needed]\n",
      "\n",
      "**APA:**\n",
      "\n",
      "[More Information Needed]\n",
      "\n",
      "## Glossary [optional]\n",
      "\n",
      "<!-- If relevant, include terms and calculations in this section that can help readers understand the model or model card. -->\n",
      "\n",
      "[More Information Needed]\n",
      "\n",
      "## More Information [optional]\n",
      "\n",
      "[More Information Needed]\n",
      "\n",
      "## Model Card Authors [optional]\n",
      "\n",
      "[More Information Needed]\n",
      "\n",
      "## Model Card Contact\n",
      "\n",
      "[More Information Needed]\n",
      "## Training procedure\n",
      "\n",
      "\n",
      "### Framework versions\n",
      "\n",
      "\n",
      "- PEFT 0.6.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_card = ModelCard.load(\"tuned_model/README.md\")\n",
    "print(model_card.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604cb6db-e133-4004-986d-298371acba35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
